---
title: "Probability and Statistics"
subtitle: "The Evolution of Computer Processors: A statistic on Common Properties"
author: "Chau Dang Minh - 2013748 <br> Provide your name guys"
output: 
  # pdf_document: default
  html_document: default
---

# Libraries

```{r message=FALSE}
# Libraries and options
library(dplyr)
library(here)
library(knitr)
library(kableExtra)
library(ggplot2)
library(ggpubr)
library(car)

options(repr.plot.width = 15, repr.plot.height =8)

# Self-defined functions
source("utils.R")

# Working directory
setwd(here())
```


# Dataset Preprocessing

## Data reading and display

```{r}
raw_cpu_data <- read.csv("dataset/Intel_CPUs.csv")
kable(head(raw_cpu_data), format = "html") %>%
  kable_styling()

raw_gpu_data <- read.csv("dataset/All_GPUs.csv")
kable(head(raw_gpu_data), format = "html") %>%
  kable_styling()
```

## Feature inspection

```{r}
cpu_columns <- colnames(raw_cpu_data)
gpu_columns <- colnames(raw_gpu_data)
intersect(cpu_columns, gpu_columns)
```
It can be seen that there are no common columns between the dataframes. However, some columns may indicate the same feature, which needed to be handled manually.

## Data cleaning

We take a look at invalid values in the dataframes

```{r}
# Count NA and empty strings
na_counts <- colSums(sapply(raw_cpu_data, 
                               function(x) 
                                 is.na(x) | x == "N/A"))

empty_counts <- colSums(sapply(raw_cpu_data, 
                               function(x) 
                                 is.character(x) & 
                                  (x == "" | x == "-")))
# Get percentage of invalid values
invalid_percentage <- (na_counts+empty_counts)/nrow(raw_cpu_data)*100

# Display
invalid_df <- 
  data.frame(Property = names(na_counts), 
             NA_Count = unname(na_counts),
             Empty_Count = unname(empty_counts),
             Invalid_Percentage = unname(invalid_percentage)) %>%
  arrange(desc(Invalid_Percentage))

kable(invalid_df, format = "html") %>% 
  kable_styling()
```

The dataframes to inference must not have any invalid values. Therefore, we select some features and instances from the original dataframes. Here we firstly select features where invalid percentage exceeds our threshold $\texttt{valid\_percentage}$. Then select valid instances and filter features for the last time. Note that if the $\texttt{valid\_percentage}$ is low, the more features are retained, implying that less instances left.

```{r}
filtered_cpu_data <- filtered_data(raw_cpu_data, valid_percentage=0.8)

is_valid <- function(value) {
  value <- tolower(trimws(value))
  return(!is.na(value)
         & !is.null(value)
         & !value == ""
         & !value == "n/a"
         & !value == "-"
         & !grepl("missing", value)
         & !grepl("unknown", value))
}

filtered_cpu_data <- 
  filtered_cpu_data[
    apply(filtered_cpu_data, 1, 
          function(row) 
            all(sapply(row, is_valid))), ]

selected_cpu_data <- filtered_cpu_data[]
selected_cpu_data <- unique(selected_cpu_data)

kable(head(selected_cpu_data), format = "html") %>%
  kable_styling()
```

For $\texttt{valid\_percentage}=0.8$, 1303 out of 2283 are retained for further analysis.

```{r}
colnames(selected_cpu_data)
```
```{r}
colnames(raw_cpu_data)
```


## Data Precomputations
1. Extract $\texttt{Release_Date}$ string to number pair $\texttt{Release_Year}$ and $\texttt{Release_Quarter}$.
2. Convert $\texttt{Recommended_Customer_Price}$ to number. If a range is presented, take the average.

```{r}
month_to_quarter <- function(month) {
  quarter <- switch(month,
    "Jan" = "1",
    "Feb" = "1",
    "Mar" = "1",
    "Apr" = "2",
    "May" = "2",
    "Jun" = "2",
    "Jul" = "3",
    "Aug" = "3",
    "Sep" = "3",
    "Oct" = "4",
    "Nov" = "4",
    "Dec" = "4",
    "Unknown")
    return(quarter)
}

recommended_price <- function(price_range) {
  if(grepl('-', price_range)) {
    range <- strsplit(price_range, " - ")[[1]]
    return((as.double(range[1]) + as.double(range[2])) / 2)
  }
  return (price_range)
}

names(selected_cpu_data)[names(selected_cpu_data) == "Launch_Date"] <- "Release_Date"

processed_cpu_data <- selected_cpu_data

processed_cpu_data$Release_Year <- 
  as.integer(sub("Q[1-4]'(\\d+)", "\\1",
    gsub("\\s+", "", selected_cpu_data$Release_Date)))
processed_cpu_data$Release_Year <- 
  ifelse(processed_cpu_data$Release_Year > 60, 
         1900 + processed_cpu_data$Release_Year, 
         2000 + processed_cpu_data$Release_Year)

processed_cpu_data$Release_Quarter <- 
  as.integer(sub("Q([1-4])'.*", "\\1",
    gsub("\\s+", "", selected_cpu_data$Release_Date)))

processed_cpu_data <- processed_cpu_data %>%
  mutate(
    Recommended_Customer_Price = as.double(sapply(gsub("[\\$,]", "", Recommended_Customer_Price), recommended_price))
  )

processed_cpu_data$Lithography <- 
  as.integer(gsub("nm", "", 
                 processed_cpu_data$Lithography))

kable(head(processed_cpu_data), format = "html") %>%
  kable_styling()
```

# Descriptive Statistics

```{r}
litho_year <- processed_cpu_data %>% 
  group_by(Release_Year) %>%
  summarize(mean_litho = mean(Lithography),
            median_litho = median(Lithography),
    .groups = "drop"
  )

ggplot(litho_year, aes(x = Release_Year)) +
  geom_line(aes(y = mean_litho, color = "Mean")) +
  geom_line(aes(y = median_litho, color = "Median")) +
  scale_color_manual(values = c("Mean" = "blue", "Median" = "red")) +
  labs(x = "Year", y = "Lithography", title = "Mean and Median Lithography by Year") +
  scale_x_continuous(breaks = seq(min(litho_year$Release_Year), max(litho_year$Release_Year),
  by = 1)) +
  theme_minimal()
```


# Inferential Statistics

## Two-way ANOVA 
```{r}

shapiro.test(processed_cpu_data$nb_of_Cores)

ggqqplot(processed_cpu_data$nb_of_Cores)

leveneTest(nb_of_Cores~Product_Collection*Vertical_Segment, data = processed_cpu_data)


new_data <- processed_cpu_data[processed_cpu_data$Product_Collection %in% 
                                          c("Core", "Legacy") & 
                                          processed_cpu_data$Vertical_Segment %in% 
                                          c("Desktop", "Embedded", "Mobile"),]

Product_Collection <- as.factor(new_data$Product_Collection)
Vertical_Segment <- as.factor(new_data$Vertical_Segment)
nb_of_Cores <- new_data$nb_of_Cores

av <- aov(nb_of_Cores ~ Product_Collection*Vertical_Segment, data = new_data)
summary(av)
``